{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you're given to task to build your own neural network. You're not allowed to use any libraries that facilitate building a network though! You're going to build it from scratch... with just raw mathematics and Numpy! Don't worry, most of the code will have been written for you. In the end, you will be tasked to train this neural network and get the highest accuracy score on the MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are some activation functions you can use in your neural network\n",
    "\n",
    "# RELU Activation function.\n",
    "def relu(x):\n",
    "    return np.maximum(0.0, x)\n",
    "\n",
    "\n",
    "# Sigmoid activation function.\n",
    "def sig(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# Softmax activation function.\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum()\n",
    "\n",
    "\n",
    "# Derivative of softmax.\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "# Derivative of sigmoid.\n",
    "def sigmoid_derivative(x):\n",
    "    sigmoid_x = 1 / (1 + np.exp(-x))\n",
    "    return sigmoid_x * (1 - sigmoid_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This class defines the neural network. This network will have one hidden layer. It has the following methods:\n",
    "# __init__ - Initialises the neural network.\n",
    "# backpropagation - Backpropogates through the network to update weights and biases.\n",
    "# predict - Predicts the input.\n",
    "# train - Trains the neural network.\n",
    "# The neural network has the following attributes:\n",
    "# iNodes - The input nodes.\n",
    "# hNodes - The hidden nodes.\n",
    "# oNodes - The output nodes.\n",
    "# wih - The weights for the input and hidden layers.\n",
    "# who - The weights for the hidden and output layers.\n",
    "# lr - The learning rate.\n",
    "# activation_function - The activation function.\n",
    "\"\"\"\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    # Initialise the neural network.\n",
    "    def __init__(self, iNodes, hNodes, oNodes, learningRate):\n",
    "        # Set the nodes in each layer.\n",
    "        self.iNodes = iNodes\n",
    "        self.hNodes = hNodes\n",
    "        self.oNodes = oNodes\n",
    "\n",
    "        # The weights for the input and hidden layers.\n",
    "        self.wih = (np.random.rand(self.hNodes, self.iNodes) - 0.5)\n",
    "\n",
    "        # The weights for the hidden and output layers. \n",
    "        self.who = (np.random.rand(self.oNodes, self.hNodes) - 0.5)\n",
    "\n",
    "        # The Learning rate\n",
    "        self.lr = learningRate\n",
    "\n",
    "        # The activation function. Right now it is set to sigmoid.\n",
    "        self.activation_function = lambda x: sig(x)\n",
    "        pass\n",
    "\n",
    "    # Function for backpropogation through the network to update weights and biases.\n",
    "    def backpropagation(self, inputs, targets, fOutputs, hOutputs):\n",
    "        \"\"\"This method backpropogates through the network to update weights and biases.\n",
    "            It updated the layer for the hidden output and the input hidden.\"\"\"\n",
    "        # Backpropogation\n",
    "        # Getting the output layer error -> (target - actual)\n",
    "        oErrors = targets - fOutputs\n",
    "\n",
    "        # Getting the error of the hidden layers.\n",
    "        hErrors = np.dot(self.who.T, oErrors)\n",
    "\n",
    "        # Updating the weights for hidden and output layers.\n",
    "        self.who += self.lr * np.dot((oErrors * fOutputs * (1.0 - fOutputs)), np.transpose(hOutputs))\n",
    "\n",
    "        # Updating the weights for input and hidden layers.\n",
    "        self.wih += self.lr * np.dot((hErrors * hOutputs * (1.0 - hOutputs)), np.transpose(inputs))\n",
    "\n",
    "    # Function for predicting the input.\n",
    "    def predict(self, iList):\n",
    "        \"\"\"This method predicts the input.\n",
    "            It takes an input and returns an output which is calculated by the activation function. \"\"\"\n",
    "        # List converting to 2d array.\n",
    "        inputs = np.array(iList, ndmin=2).T\n",
    "\n",
    "        hinputs = np.dot(self.wih, inputs)\n",
    "        houtputs = self.activation_function(hinputs)\n",
    "\n",
    "        finputs = np.dot(self.who, houtputs)\n",
    "        return self.activation_function(finputs)\n",
    "\n",
    "    # Function for training the neural network.\n",
    "    def train(self, iList, tar_List):\n",
    "        \"\"\"This method trains the neural network. It receives an input list and a target list.\n",
    "            With these given lists the nn is being trained. Backpropagation is used in this method.\"\"\"\n",
    "        # List converting to 2d array.\n",
    "        inputs = np.array(iList, ndmin=2).T\n",
    "        targets = np.array(tar_List, ndmin=2).T\n",
    "\n",
    "        # calculate signals into hidden layer.\n",
    "        hInputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        # calculate the signals emerging from hidden layer.\n",
    "        hOutputs = self.activation_function(hInputs)\n",
    "\n",
    "        # calculate signals into final output layer\n",
    "        fInputs = np.dot(self.who, hOutputs)\n",
    "\n",
    "        fOutputs = self.activation_function(fInputs)\n",
    "\n",
    "        # Apply backpropagation.\n",
    "        self.backpropagation(inputs=inputs, targets=targets, fOutputs=fOutputs, hOutputs=hOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(data, epochs):\n",
    "    \"\"\"This method trains the neural network. It can take a while.\n",
    "        It init's the inputs at 0.01 and the targets at 0.99\"\"\"\n",
    "    print(\"Training can take a while... sit back and relax :)\")\n",
    "    for i in range(epochs):\n",
    "        print(f'Epoch: {i + 1}')\n",
    "        for record in data[1:]:\n",
    "            # split the line by the ',' commas\n",
    "            values = record.split(',')\n",
    "\n",
    "            # normalize the data.\n",
    "            inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "            # create the target output values, array of output_nodes.\n",
    "            targets = np.zeros(onodes) + 0.01\n",
    "\n",
    "            # values[0] is the target label for this record\n",
    "            targets[int(values[0])] = 0.99\n",
    "\n",
    "            # Train the network\n",
    "            nn.train(inputs, targets)\n",
    "\n",
    "        # Calculate the accuracy of the training.\n",
    "        accuracy = calculate_train_accuracy(nn, data)\n",
    "        print(f'Training accuracy at epoch {i + 1}: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(data):\n",
    "    \"\"\"This method tests the neural network. It loops through all the records in the test data set.\n",
    "        While looping, it predicts the result of the input. \"\"\"\n",
    "    # go through all the records in the test data set\n",
    "    for record in data[1:]:\n",
    "        # split the record by the ',' commas\n",
    "        values = record.split(',')\n",
    "\n",
    "        # correct answer is first value\n",
    "        y_true = int(values[0])\n",
    "\n",
    "        # Normalize the data\n",
    "        inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        # Test the network by predicting\n",
    "        outputs = nn.predict(inputs)\n",
    "\n",
    "        # the index of the highest value corresponds to the label\n",
    "        y_pred = np.argmax(outputs)\n",
    "\n",
    "        # append correct or incorrect to list to calculate accuracy\n",
    "        if y_pred == y_true:\n",
    "            # if guess = correct +1\n",
    "            score_progress.append(1)\n",
    "        else:\n",
    "            # if guess is not correct +0\n",
    "            score_progress.append(0)\n",
    "            # Save the incorrect guess data, so it can be plotted later.\n",
    "            incorrect_guesses.append({\n",
    "                \"correct_label\": y_true,\n",
    "                \"guessed_label\": y_pred,\n",
    "                \"values\": record\n",
    "            })\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_train_accuracy(nn, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for record in data[1:]:\n",
    "        values = record.split(',')\n",
    "        inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        targets = int(values[0])\n",
    "        outputs = nn.predict(inputs)\n",
    "        predicted_label = np.argmax(outputs)\n",
    "        if predicted_label == targets:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_accuracy():\n",
    "    \"\"\"This method calculates the accuracy of the model on the test set.\"\"\"\n",
    "    scorecard_array = np.asfarray(score_progress)\n",
    "    print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    \"\"\"This method gets the test_data from the mnist_test file.\"\"\"\n",
    "    test_data_file = open(\"mnist_data/mnist_test.csv\", 'r')\n",
    "    test_data_list = test_data_file.readlines()\n",
    "    test_data_file.close()\n",
    "    return test_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    \"\"\"This method gets the train_data from the mnist_train file.\"\"\"\n",
    "    train_data_file = open(\"mnist_data/mnist_train.csv\", 'r')\n",
    "    train_data_list = train_data_file.readlines()\n",
    "    train_data_file.close()\n",
    "    return train_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_incorrect_guesses(nrows, ncols):\n",
    "    \"\"\"This method checks the incorrect guesses and plots them. You can define how many you want to see.\n",
    "    The amount that will be shown is nrows * ncols\"\"\"\n",
    "\n",
    "    # Init figure.\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    # Loop through the amount of images wanted to be seen.\n",
    "    for i in range(nrows * ncols):\n",
    "        # Retrieve the data needed.\n",
    "        correct_label = incorrect_guesses[i]['correct_label']\n",
    "        guessed_label = incorrect_guesses[i]['guessed_label']\n",
    "        values = incorrect_guesses[i]['values'].split(',')\n",
    "        # Convert to array so it can be plotted.\n",
    "        img_array = np.asfarray(values[1:]).reshape((28, 28))\n",
    "\n",
    "        # Add the number plot on correct place.\n",
    "        fig.add_subplot(nrows, ncols, i + 1)\n",
    "        plt.imshow(img_array, cmap='Greys',\n",
    "                   interpolation='None')\n",
    "        plt.title(f'Number {str(correct_label)} seen as {str(guessed_label)}')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init parameters for network.\n",
    "inodes, hnodes, onodes, learning_rate = 784, 200, 10, 0.1\n",
    "\n",
    "# init network\n",
    "nn = NeuralNetwork(iNodes=inodes, hNodes=hnodes, oNodes=onodes, learningRate=learning_rate)\n",
    "\n",
    "# Arrays to keep track of the score of the network and the incorrect guesses.\n",
    "score_progress = []\n",
    "incorrect_guesses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network with x amount of epochs.\n",
    "train_nn(data=get_train_data(), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "test_nn(data=get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance.\n",
    "calc_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the incorrect guesses. Amount of plots will be nrows * ncols.\n",
    "check_incorrect_guesses(nrows=3, ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've trained and tested your network, try to get the best results by tweaking the parameters!\n",
    "\n",
    "For an extra challenge: Not only try to tweak the parameters, but try to change the structure of the network itself to improve results. (for example add another hidden layer or change the activation function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
