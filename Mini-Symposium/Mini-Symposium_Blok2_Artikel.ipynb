{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977af4e4",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Context](#context)\n",
    "  - [What will you learn](#what-you-will-learn)\n",
    "  - [Prerequisites](#prerequisites)\n",
    "  - [Introduction](#introduction)\n",
    "  - [Approach Overview](#approach-overview) \n",
    "  - [Scope and Limitations](#scope-and-limitations)\n",
    "- [Coding](#coding)\n",
    "  - [Step 1: Setting up the environment](#step-1-setting-up-the-environment)\n",
    "  - [Step 2: Loading the data](#step-2-loading-the-data)\n",
    "  - [Step 3: Filtering Languages](#step-3-filtering-languages)\n",
    "  - [Step 4: Data Preperation](#step-4-data-preperation)\n",
    "    - [Step 4.1: Tokenization](#step-41-tokenization)\n",
    "    - [Step 4.2: Bag-of-Words](#step-42-bag-of-words)\n",
    "    - [Step 4.3: Encode Labels](#step-43-encode-labels)\n",
    "  - [Step 5: Train the classifier](#step-5-train-the-classifier)\n",
    "  - [Step 6: Evaluation](#step-6-evaluate)\n",
    "- [Conclusion](#conclusion)\n",
    "- [Sources](#sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63c3e0",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682bdb92",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "By the end of this tutorial, you will understand how to: \n",
    "- Prepare multilingual textual data for text classification \n",
    "- Build a shared vocabulary across languages \n",
    "- Represent text using a Bag-of-Words approach \n",
    "- Train and evaluate a linear multi-class classifier \n",
    "- Interpret predictions and confidence scores \n",
    "- Make sense of everything mentioned in this list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83928260",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "You will need the following to be able to follow the tutorial\n",
    "- Estimated time: 30-60 minutes\n",
    "- 2GB Free Storage \n",
    "- 4GB RAM\n",
    "- Windows 10/11\n",
    "- Visual Studio Code + Jupyter Extension\n",
    "- Anaconda (For easy environment management)\n",
    "- Basic python knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b0c2f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this tutorial, we will build a language classifier. A language classifier is a model that can predict which language a sentence is written in.\n",
    "\n",
    "Language classification is one of the most basic problems in Natural Language Processing (NLP). Because of this, it is a great starting point if you are new to NLP or machine learning in general. The task is easy to understand, yet it introduces many of the core concepts used in more advanced NLP systems.\n",
    "\n",
    "Language classification also has many practical applications in the real world. One example you interact with almost every day is search engines such as Google or Bing. When you type a query in a certain language, the search engine first detects that language and then returns results in the same language. Also many translation tools provide a \"Detect Language\" function where you can type and the tool figures out what language it is, think of tools like Google Translate and DeepL.\n",
    "\n",
    "In the next sections, we will go step by step through the process of building a simple language classifier, starting from loading a dataset and ending with training and evaluating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030905f",
   "metadata": {},
   "source": [
    "## Approach Overview\n",
    "\n",
    "This tutorial is inspired by Deep Learning with Python (3rd Edition) by François Chollet, specifically chapter 14 text classification [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification). In this chapter, different ways of working with text are introduced, such as models that look at word order (sequence-based models) versus models that only care about which words appear (set-based models).\n",
    "\n",
    "In this tutorial, we deliberately keep things simple. We use a set-based approach with word-level tokenization, which means the model predicts the language of a sentence by looking only at which words are present in that sentence, not at their order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697051e4",
   "metadata": {},
   "source": [
    "## Scope and Limitations\n",
    "\n",
    "To keep the problem well-defined and clear, we restrict the model to a small set of languages. The classifier will only predict one of the languages it was trained on.\n",
    "\n",
    "It is important to note that:\n",
    "- This model cannot detect unsupported languages.\n",
    "- Predicted probabilities represent the model’s relative confidence among the supported languages, not an absolute measure of correctness.\n",
    "- A high predicted probability does not guarantee that the input truly belongs to the predicted language.\n",
    "\n",
    "These limitations are not flaws, but expected properties of simple set-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118ab2c",
   "metadata": {},
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9981ca",
   "metadata": {},
   "source": [
    "## Step 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b01e8b",
   "metadata": {},
   "source": [
    "We will work using python environments. That means we will work inside of a python container which isn't being influenced by anything else on your pc. This way we can make sure that your code will run exactly the same way as mine.\n",
    "\n",
    "First we need to create a python environment, which we will name `myenv_llm`, with the version `3.10.15`. This can be done by opening the `Command Prompt` and running the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def811d7",
   "metadata": {},
   "source": [
    "`conda create -n myenv_llm python=3.10.15`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99082cb3",
   "metadata": {},
   "source": [
    "Once the environment is created, you can select the newly created environment as interpreter in visual studio code. Do `CTRL + SHIFT + P` type `Python: Select Interpreter` and click on it. This should show a list of environments, try to find the newly created environment `myenv_llm`.\n",
    "\n",
    "To test if it worked we can run the code cel below using `CTRL + ENTER`. This will prompt you to install the ipykernel package, proceed if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe48720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6047b",
   "metadata": {},
   "source": [
    "To prepare the environment for the rest of the tutorial we need to install the following 4 packages:\n",
    "- **pandas** [[2]](#2-pandas-developers-getting-started-pandas-233-documentation-httpspandaspydataorgpandas-docsversion233getting_startedindexhtml): to analyze and modify data\n",
    "- **fsspec** [[3]](#3-fsspec-developers-fsspec-documentation-latest-httpsfilesystem-specreadthedocsioenlatest): to read dataset files, especially from remote / virtual filesystems\n",
    "- **huggingface_hub** [[4]](#4-hugging-face-developers-huggingface_hub-documentation-latest-httpshuggingfacecodocshuggingface_hub): to download datasets from Hugging Face (A popular website for datasets)\n",
    "- **scikit-learn** [[5]](#5-scikit-learn-developers-scikit-learn-172-documentation-httpsscikit-learnorg17): to encode labels\n",
    "- **matplotlib** [[6]](#6-matplotlib-developers-matplotlib-3108-documentation-httpsmatplotliborg3108): to plot fancy demographics\n",
    "- **seaborn** [[7]](#7-seaborn-developers-seaborn-documentation-httpsseabornpydataorg): to plot fancy demographics\n",
    "\n",
    "These packages can be installed by running the following code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==2.3.3 fsspec==2025.12.0 huggingface_hub==1.2.3 scikit-learn==1.7.2 matplotlib==3.10.8 seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb6605",
   "metadata": {},
   "source": [
    "We can check if the your python and package versions match the ones used in the tutorial by running the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1386a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.15 (should be 3.10.15)\n",
      "pandas version: 2.3.3 (should be 2.3.3)\n",
      "fsspec version: 2025.12.0 (should be 2025.12.0)\n",
      "huggingface_hub version: 1.2.3 (should be 1.2.3)\n",
      "scikit-learn version: 1.7.2 (should be 1.7.2)\n",
      "matplotlib version: 3.10.8 (should be 3.10.8)\n",
      "seaborn version: 0.13.2 (should be 0.13.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import fsspec\n",
    "import huggingface_hub\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Python version:\", sys.version[:7], \"(should be 3.10.15)\")\n",
    "print(\"pandas version:\", pd.__version__, \"(should be 2.3.3)\")\n",
    "print(\"fsspec version:\", fsspec.__version__, \"(should be 2025.12.0)\")\n",
    "print(\"huggingface_hub version:\", huggingface_hub.__version__, \"(should be 1.2.3)\")\n",
    "print(\"scikit-learn version:\", sklearn.__version__, \"(should be 1.7.2)\")\n",
    "print(\"matplotlib version:\", matplotlib.__version__, \"(should be 3.10.8)\")\n",
    "print(\"seaborn version:\", sns.__version__, \"(should be 0.13.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87010926",
   "metadata": {},
   "source": [
    "Now that we have the environment working inside visual studio code, we can start coding! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cb2d1",
   "metadata": {},
   "source": [
    "## Step 2: Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a07e0a",
   "metadata": {},
   "source": [
    "As dataset we will use the *Language Identification dataset by Papluca* [[8]](#8-papluca-language-identification-dataset-hugging-face-httpshuggingfacecodatasetspaplucalanguage-identification). This dataset is an excellent dataset for a basic language classification exercise. This dataset consists of reviews posted on Amazon in a total of 20 languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd7575e",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6458b33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thezo\\anaconda3\\envs\\myenv_llm2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pt</td>\n",
       "      <td>os chefes de defesa da estónia, letónia, lituâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>размерът на хоризонталната мрежа може да бъде ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zh</td>\n",
       "      <td>很好，以前从不去评价，不知道浪费了多少积分，现在知道积分可以换钱，就要好好评价了，后来我就把...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>th</td>\n",
       "      <td>สำหรับ ของเก่า ที่ จริงจัง ลอง   honeychurch  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>Он увеличил давление .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>ja</td>\n",
       "      <td>本格的なゲーミングヘッドホンでした。 今まで使ってた1万円するパナソニックのヘッドホンは何だ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>el</td>\n",
       "      <td>Ναι , ξέρω ένα που είναι ακόμα έτσι , αλλά αυτ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>ur</td>\n",
       "      <td>اور مجھے اس ملک کے بارے میں معلوم نہیں ہے کہ گ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>es</td>\n",
       "      <td>Se me rompió uno al sacarlo del cargador. Cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>hi</td>\n",
       "      <td>कोसोवो कथा का विवरण जिसमें स ् थानीय राष ् ट ्...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text\n",
       "0         pt  os chefes de defesa da estónia, letónia, lituâ...\n",
       "1         bg  размерът на хоризонталната мрежа може да бъде ...\n",
       "2         zh  很好，以前从不去评价，不知道浪费了多少积分，现在知道积分可以换钱，就要好好评价了，后来我就把...\n",
       "3         th  สำหรับ ของเก่า ที่ จริงจัง ลอง   honeychurch  ...\n",
       "4         ru                             Он увеличил давление .\n",
       "...      ...                                                ...\n",
       "69995     ja  本格的なゲーミングヘッドホンでした。 今まで使ってた1万円するパナソニックのヘッドホンは何だ...\n",
       "69996     el  Ναι , ξέρω ένα που είναι ακόμα έτσι , αλλά αυτ...\n",
       "69997     ur  اور مجھے اس ملک کے بارے میں معلوم نہیں ہے کہ گ...\n",
       "69998     es  Se me rompió uno al sacarlo del cargador. Cali...\n",
       "69999     hi  कोसोवो कथा का विवरण जिसमें स ् थानीय राष ् ट ्...\n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"hf://datasets/papluca/language-identification/train.csv\")\n",
    "df_validation = pd.read_csv(\"hf://datasets/papluca/language-identification/valid.csv\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a02cd",
   "metadata": {},
   "source": [
    "This is a brief overview of what our dataset looks like. it contains a label and text per row, and has a total of 70000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caeb3ac",
   "metadata": {},
   "source": [
    "Checking present languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6287622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pt', 'bg', 'zh', 'th', 'ru', 'pl', 'ur', 'sw', 'tr', 'es', 'ar',\n",
       "       'it', 'hi', 'de', 'el', 'nl', 'fr', 'vi', 'en', 'ja'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8668e7",
   "metadata": {},
   "source": [
    "## Step 3: Filtering Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7d423",
   "metadata": {},
   "source": [
    "20 languages is a bit much for a simple tutorial. Therefore we will filter down the dataset to just 5 languages. We will filter on the following languages:\n",
    "- English\n",
    "- Spanish\n",
    "- Italian\n",
    "- Portuguese\n",
    "- Russian\n",
    "\n",
    "These languages are chosen for the following reasons: English to have an interpretable language. Spanish, Italian and Portguese since those 3 languages are closely related and share many words. And Russian so we have one language that uses a different alphabet and doesn't look anything like the other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fd6ae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Filter the dataset on these 5 languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a348c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pt</td>\n",
       "      <td>os chefes de defesa da estónia, letónia, lituâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru</td>\n",
       "      <td>Он увеличил давление .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pt</td>\n",
       "      <td>Duas raças diferentes de cães castanhos e bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es</td>\n",
       "      <td>Un producto de una calidad y capacidad increíb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it</td>\n",
       "      <td>Una donna sta affettando della carne.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17495</th>\n",
       "      <td>en</td>\n",
       "      <td>Color bleeds. Softness is lost after only one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>es</td>\n",
       "      <td>Tuve que devolverlos, el auricular izquierdo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>it</td>\n",
       "      <td>Il governo israeliano autorizza nuovi insediam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>es</td>\n",
       "      <td>Muy bueno para gente con alergias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>es</td>\n",
       "      <td>Se me rompió uno al sacarlo del cargador. Cali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text\n",
       "0         pt  os chefes de defesa da estónia, letónia, lituâ...\n",
       "1         ru                             Он увеличил давление .\n",
       "2         pt  Duas raças diferentes de cães castanhos e bran...\n",
       "3         es  Un producto de una calidad y capacidad increíb...\n",
       "4         it              Una donna sta affettando della carne.\n",
       "...      ...                                                ...\n",
       "17495     en  Color bleeds. Softness is lost after only one ...\n",
       "17496     es  Tuve que devolverlos, el auricular izquierdo s...\n",
       "17497     it  Il governo israeliano autorizza nuovi insediam...\n",
       "17498     es                  Muy bueno para gente con alergias\n",
       "17499     es  Se me rompió uno al sacarlo del cargador. Cali...\n",
       "\n",
       "[17500 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_languages = [\"en\", \"es\", \"it\", \"pt\", \"ru\"]\n",
    "\n",
    "# filter the train and val set\n",
    "df_train_filtered = df_train[df_train[\"labels\"].isin(target_languages)].reset_index(drop=True)\n",
    "df_validation_filtered = df_validation[df_validation[\"labels\"].isin(target_languages)].reset_index(drop=True)\n",
    "\n",
    "# sample of the filtered train set\n",
    "df_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c841c6b",
   "metadata": {},
   "source": [
    "We can make sure it worked by printing the unique labels once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0ac3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pt', 'ru', 'es', 'it', 'en'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered['labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee200af",
   "metadata": {},
   "source": [
    "Perfect! We managed to exclude all the rows that contain languages we don't want in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac5a78",
   "metadata": {},
   "source": [
    "## Step 4: Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cec169",
   "metadata": {},
   "source": [
    "Now that the dataset is filtered to just 5 languages, we can start preparing the data for machine learning! In our dataframe we have one columns for all the labels and one for all the reviews. We want to load both into variables separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3fa80",
   "metadata": {},
   "source": [
    "Load in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c2120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['os chefes de defesa da estónia, letónia, lituânia, alemanha, itália, espanha e eslováquia assinarão o acordo para fornecer pessoal e financiamento para o centro.',\n",
       " 'Он увеличил давление .',\n",
       " 'Duas raças diferentes de cães castanhos e brancos brincam na praia.',\n",
       " 'Un producto de una calidad y capacidad increíbles que será el placer de todo amante de la tecnología',\n",
       " 'Una donna sta affettando della carne.',\n",
       " 'Эти инструменты приведены вместе в mantinada songs с рифм тахикардия текстов .',\n",
       " 'não usa muito o botão de pesquisa, pois não?',\n",
       " 'Jactos do exército matam 38 militantes em ataques aéreos no Noroeste do Paquistão',\n",
       " 'El tacto es horrible, el dedo se engancha cuando deslizas',\n",
       " 'Casco para decoración. No homologado y poco más que un casco de juguete, si tienes un accidente es mejor no llevar nada en la cabeza antes que llevar un casco como este. Al igual que las gafas que son de plástico inyectado y de pésima calidad. Solo hay una cosa que lo justifique, el precio.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train = df_train_filtered[\"text\"].tolist()\n",
    "reviews_val   = df_validation_filtered[\"text\"].tolist()\n",
    "\n",
    "# sample reviews in train set\n",
    "reviews_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4697d8",
   "metadata": {},
   "source": [
    "Load in labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b376cda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pt', 'ru', 'pt', 'es', 'it', 'ru', 'pt', 'pt', 'es', 'es']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = df_train_filtered['labels'].tolist()\n",
    "labels_val   = df_validation_filtered['labels'].tolist()\n",
    "\n",
    "# sample labels in train set\n",
    "labels_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eea0e",
   "metadata": {},
   "source": [
    "### Step 4.1: Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790978c1",
   "metadata": {},
   "source": [
    "Traditionally in machine learning, you input data with a label so the model can learn the relations between the data and the label, after the model learned the relations between the data and the labels, you can input data without labels into the model, which then can predict an output. In our case, that translates to inputting the amazon reviews (our data) and the languages (our labels) the model, so it can learn the relations between them, and after the model learned the relations, we can enter an amazon review without a label (or any other sort of text data) and expect a predicted language as output. Sadly, it's not as simple as inputting textual data and labels into a model and receiving a language prediction as output. Models rely on numbers for both input and output. Therefore, we need to convert text into numbers so the model can process it. \n",
    "\n",
    "There are multiple ways to convert textual data into numeric data. In this tutorial we will use the simplest form of tokenization, *word-level tokenization* in combination with a *vocabulary* and a *bag-of-words* representation [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification) (bag-of-words will be covered in #4.2). Each of these terms will be explained one by one, starting with Word-Level Tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcf08e",
   "metadata": {},
   "source": [
    "#### Word-Level Tokenization\n",
    "Word-level tokenization is the process of splitting a sentence into individual tokens (or in our case, words. since we are using word-level tokenization). \n",
    "\n",
    "For example, the sentence:\n",
    "\n",
    "`the quick brown fox jumps over the lazy dog.`\n",
    "\n",
    "can be tokenized into:\n",
    "\n",
    "`['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']`\n",
    "\n",
    "\n",
    "Notice that each word, as well as the punctuation, becomes a separate token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a56761",
   "metadata": {},
   "source": [
    "#### Vocabulary and Encoding\n",
    "Once we have tokens, we need to convert each token into a number for our model to understand. This is done using a vocabulary, which assigns a unique number to each token. \n",
    "\n",
    "For example, using the following vocabulary:\n",
    "\n",
    "- 0 = `[UNKNOWN WORD]` (0 is always reserved for unknown words)\n",
    "- 1 = `the`  \n",
    "- 2 = `quick`  \n",
    "- 3 = `brown`  \n",
    "- 4 = `fox`  \n",
    "- 5 = `jumps`  \n",
    "- 6 = `over`  \n",
    "- 7 = `lazy`  \n",
    "- 8 = `dog`  \n",
    "- 9 = `.`  \n",
    "\n",
    "We can encode our previously tokenized sentence to the following encoding:\n",
    "\n",
    "```py\n",
    "Tokenized: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
    "Encoded:   [  1  ,   2    ,    3   ,   4  ,   5    ,   6   ,   1  ,   7   ,   8  ,  9 ]\n",
    "```\n",
    "\n",
    "The word `the` appears twice, so it's encoded as the number `1` in both cases. Now that we understand the theory, it's time for the implementation. We will start by building a vocabulary, since tokenizers depend on a vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7900f",
   "metadata": {},
   "source": [
    "Define function to build vocabulary from textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f652371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def build_word_vocabulary(texts, max_size):\n",
    "    counter = collections.Counter()\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r\"[\\w]+|[.,!?;]\", text.lower())\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocabulary = [\"[UNK]\"]\n",
    "    for token, _ in counter.most_common(max_size - 1):\n",
    "        vocabulary.append(token)\n",
    "\n",
    "    return {token: idx for idx, token in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e998bce",
   "metadata": {},
   "source": [
    "Build vocabulary on example sentence mentioned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7c63ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary (from example sentence):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'[UNK]': 0,\n",
       " 'the': 1,\n",
       " 'quick': 2,\n",
       " 'brown': 3,\n",
       " 'fox': 4,\n",
       " 'jumps': 5,\n",
       " 'over': 6,\n",
       " 'lazy': 7,\n",
       " 'dog': 8,\n",
       " '.': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = [\"the quick brown fox jumps over the lazy dog.\"]\n",
    "vocabulary_example = build_word_vocabulary(text_example, max_size=10)\n",
    "\n",
    "print(\"vocabulary (from example sentence):\")\n",
    "vocabulary_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b103a6c",
   "metadata": {},
   "source": [
    "The vocabulary is exactly similar to the example given earlier. Now that we built our vocabulary, we can use it in combination with the wordtokenizer to encode textual data into numeric data.\n",
    "\n",
    "Define the WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14a83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(r\"[\\w]+|[.,!?;]\", text)\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc20be8",
   "metadata": {},
   "source": [
    "Create instance of the wordtokenizer with the example vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5672018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(vocabulary_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f5c8f",
   "metadata": {},
   "source": [
    "We can use the tokenizer to encode textual data into numeric data\n",
    "\n",
    "Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc633ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 1, 7, 8, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1f2e0",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82962156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 4, 5, 6, 1, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the quick orange fox jumps over the lazy dog.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa286a2",
   "metadata": {},
   "source": [
    "Note how in the second example, the tokenizer returns a 0. This is because the vocabulary has never seen the word `orange` and therefore falls back to 0. This will be more clear if we try to encode a sentence that is completely different.\n",
    "\n",
    "Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf26b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Obviously, I am having the time of my life following this tutorial!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a39c6f",
   "metadata": {},
   "source": [
    "Great! We managed to fill a vocabulary with the sentence: `\"the quick brown fox jumps over the lazy dog.\"` and use it to encode textual data into numeric data. However, building a vocabulary off of a single sentence isn't pratical, since it results in a very limited vocabulary. For most text classification problems, a vocabulary of 20 thousand words is a good starting point [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification). We can achieve this by using our dataset to fill the vocabulary instead.\n",
    "\n",
    "Earlier we splitted our train data into `reviews_train` and `label_train`. Now we can use the reviews inside `reviews_train` to fill a vocabulary. This vocabulary will contain a combination of unique words over 5 different languages. The top 20.000 most frequent words will make it inside the vocabulary. Other words in `reviews_train` that don't appear frequent enough are left out of the vocabulary.\n",
    "\n",
    "> *Why not allow all the words of the training data in the vocabulary?*\n",
    ">\n",
    "> *A bigger vocabulary means longer processing time. In some scenario's this could be a good trade-off. However, if we start adding every single word to the vocabulary, even words that only appear once, it wouldn't improve model performance, only slow it down. The goal of the vocabulary is to make a collection of words that appear frequent, not to add as many words as possible.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9869f",
   "metadata": {},
   "source": [
    "Fill vocabulary with reviews from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b1dab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary (from training set):\n",
      "\n",
      "First 10 and last 10 (word, index):\n",
      "'[UNK]': 0,\n",
      "'.': 1,\n",
      "',': 2,\n",
      "'a': 3,\n",
      "'the': 4,\n",
      "'de': 5,\n",
      "'i': 6,\n",
      "'que': 7,\n",
      "'it': 8,\n",
      "'la': 9,\n",
      "...\n",
      "'программами': 19990,\n",
      "'tagli': 19991,\n",
      "'smh': 19992,\n",
      "'maaruf': 19993,\n",
      "'bakhit': 19994,\n",
      "'raghdad': 19995,\n",
      "'alterações': 19996,\n",
      "'climáticas': 19997,\n",
      "'trombeta': 19998,\n",
      "'documentation': 19999,\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary (from training set):\\n\")\n",
    "vocabulary = build_word_vocabulary(reviews_train, max_size=20000)\n",
    "\n",
    "# converting from dict to list to print first and last 10 words\n",
    "vocab_items = list(vocabulary.items())\n",
    "\n",
    "print(\"First 10 and last 10 (word, index):\")\n",
    "for word, idx in vocab_items[:10]:\n",
    "    print(f\"'{word}': {idx},\")\n",
    "print(\"...\")\n",
    "for word, idx in vocab_items[-10:]:\n",
    "    print(f\"'{word}': {idx},\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9b88d",
   "metadata": {},
   "source": [
    "We managed to fill a vocabulary with the 20.000 most frequent words in the reviews train data. Now we can use our new vocabulary to define a new wordtokenizer and use it on the same example sentences as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e124f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd9e4c0",
   "metadata": {},
   "source": [
    "Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e43a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2060, 2880, 0, 0, 274, 4, 0, 751, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afeb495",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1182a6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2060, 4423, 0, 0, 274, 4, 0, 751, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the quick orange fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220fd9e7",
   "metadata": {},
   "source": [
    "Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f4ca428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3231, 2, 6, 259, 745, 4, 161, 30, 36, 1147, 5602, 25, 0, 34]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Obviously, I am having the time of my life following this tutorial!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af115866",
   "metadata": {},
   "source": [
    "These examples tell us that the words `fox`, `jumps`, `lazy` and `tutorial` do not appear (frequent enough) in the dataset to be included in the vocabulary and therefore fall back to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068e291",
   "metadata": {},
   "source": [
    "### Step 4.2: Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c44cc",
   "metadata": {},
   "source": [
    "Up until now we learned how to encode textual data into numeric data. Now, we will use this technology to prepare the data for our classifier. There are many ways to represent text as numeric data, each with their own pros and cons. For this tutorial, we will use *Bag-of-Words*, because it is the simplest way represent text as numeric data for a set-based model [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification).\n",
    "\n",
    "With bag-of-words, the language of a review is predicted by looking only at which words are present in the review. Word order and grammar are ignored. We can use the examples from earlier to explain this idea. Assume the vocabulary was created using only the sentence `\"the quick brown fox jumps over the lazy dog.\"` This results in the vocabulary of only 10 tokens. Inside a bag-of-words, each token gets their own index. Say, `\"the\"` is the word with number 1 in the vocabulary, then it will have index 1 in the bag-of-words. This will become more clear with the following examples: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa226fa4",
   "metadata": {},
   "source": [
    "First example with Vocabulary, Tokenization, Encoding and Bag-of-Words\n",
    "\n",
    "\n",
    "```py \n",
    "Vocabulary example: \n",
    "{\n",
    "    '[UNK]': 0, \n",
    "    'the': 1, \n",
    "    'quick': 2, \n",
    "    'brown': 3, \n",
    "    'fox': 4, \n",
    "    'jumps': 5, \n",
    "    'over': 6, \n",
    "    'lazy': 7, \n",
    "    'dog': 8, \n",
    "    '.': 9\n",
    "}\n",
    "Example Sentence:  \"the quick orange fox jumps over the lazy dog.\"\n",
    "Tokenized:        ['the', 'quick', 'orange', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
    "Encoded:          [1, 2, 0, 4, 5, 6, 1, 7, 8, 9]\n",
    "Bag-of-Words:     [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ce96f",
   "metadata": {},
   "source": [
    "Up until this point, everything should make sense except for the bag-of-words. The way it works is that it only checks if a word is present in the sentence. The word `'the'` is indeed present in the example, therefore in the bag-of-words, on index number 1 we see a `1`. The word `brown` is not present in our sentence, brown has the index of 3 in our vocabulary, meaning index number 3 in the bag-of-words will be `0`. Here is another example:\n",
    "\n",
    "Second example with Vocabulary, Tokenization, Encoding and Bag-of-Words\n",
    "```py\n",
    "Vocabulary: (Same)\n",
    "Example Sentence:  \"the end.\"\n",
    "Tokenized:        ['the', 'end', '.']\n",
    "Encoded:          [1, 0, 9]\n",
    "Bag-of-Words:     [1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a374269",
   "metadata": {},
   "source": [
    "As you might have noticed, the bag-of-words is always the same size as the vocabulary. This makes sense because the bag-of-words checks for each word if it the word is present in the text. If the word is present, the word's index becomes 1. If a word is absent its index remains 0. (this long array of 0s and 1s is called one-hot-encoding in the world of Machine Learning)\n",
    "\n",
    "> *Why even make a tokenizer? The encodings seem unnecessary, it seems like you just need a vocabulary and bag-of-words*\n",
    ">\n",
    "> *This is a very fair question to ask, since we indeed don't need the encodings from the tokenizer. But, there is still a reason to use one. First of all is it convenient to use a tokenizer since you have to code less yourself. Also, in many other text-classification models, tokenizers **are** a necessity, so it is definitely good to have seen it once.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da06c54",
   "metadata": {},
   "source": [
    "With this in mind, we can convert all data to bag-of-words, so the model can learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6675b69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.], shape=(20000,), dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define function\n",
    "def text_to_bow(texts, tokenizer):\n",
    "    vocab_size = len(tokenizer.vocabulary)\n",
    "    X = np.zeros((len(texts), vocab_size), dtype=\"float32\")\n",
    "    for i, text in enumerate(texts):\n",
    "        token_ids = tokenizer(text)\n",
    "        for tid in set(token_ids):\n",
    "            X[i, tid] = 1.0\n",
    "    return X\n",
    "\n",
    "X_train = text_to_bow(reviews_train, tokenizer)\n",
    "X_val   = text_to_bow(reviews_val, tokenizer)\n",
    "\n",
    "# sample a bag-of-words representation\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf1dfa",
   "metadata": {},
   "source": [
    "In the output above we can see the first bag-of-words of our train set. As expected, it outputs an array with a length of 20.000, filled with 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6593558",
   "metadata": {},
   "source": [
    "### Step 4.3: Encode Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a05376",
   "metadata": {},
   "source": [
    "As we mentioned earlier, you cannot input textual data into a model. We used tokenization, a vocabulary and bag-of-words to convert our textual data into numeric data. The problem is that our labels (The languages) are still in text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5e26233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ru', 'pt', 'pt', 'es', 'en', 'es', 'ru', 'en', 'it', 'it']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cf340",
   "metadata": {},
   "source": [
    "Since there are only 5 unique labels, we can assign each label to a number. This process is called label encoding. To do this, we will use the `LabelEncoder` from sklearn (scikit-learn) which basically does all the work for us. The label encoder converts each language into a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbeaa258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(labels_train)\n",
    "y_val_enc   = le.fit_transform(labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c27f1",
   "metadata": {},
   "source": [
    "Now our labels have numbers instead of a string. The label encoder encoded our labels the following way\n",
    "```json\n",
    "- \"en\": 0\n",
    "- \"es\": 1\n",
    "- \"it\": 2\n",
    "- \"pt\": 3\n",
    "- \"ru\": 4\n",
    "```\n",
    "We can actually see this by printing the same labels we printed before, except now we print the encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0463fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Labels: ['ru', 'pt', 'pt', 'es', 'en', 'es', 'ru', 'en', 'it', 'it']\n",
      "Encoded Labels: [4 3 3 1 0 1 4 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Labels:\", labels_train[10:20])\n",
    "print(\"Encoded Labels:\", y_train_enc[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ca463",
   "metadata": {},
   "source": [
    "## Step 5: Train the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871bfe5d",
   "metadata": {},
   "source": [
    "At this point we created our environment, loaded our data, filtered it to 5 languages, prepared the data by encoding textual data to numeric data for both the reviews and the labels. Now we can finally start modelling! \n",
    "\n",
    "For modelling we will use `LogisticRegression` [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification). Again, there are many models to choose from which all come with their own pros and cons, but for simplicity, we will use on of the most basic and commonly used models.\n",
    "\n",
    "With our encoded amazon reviews in bag-of-words `X_train`, and our encoded language labels `y_train_enc` we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53e704fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thezo\\anaconda3\\envs\\myenv_llm2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;multinomial&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multinomial&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='multinomial', random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=500,\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train_enc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccb12d",
   "metadata": {},
   "source": [
    "Once our model is done training on our train data, we can evaluate how well the model performs on data it has never seen before, the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0a1ca",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afbbb5",
   "metadata": {},
   "source": [
    "In the last chapter we will evaluate how good our model got at predicting a language off of textual data. Let's check how well our model performs on the reviews.\n",
    "\n",
    "The model scores rounded about 0.9993 on the train set and 0.9948 on the validation set. These numbers convert to 99.93% accuracy on the trainset and 99.48% on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0dddf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9993714285714286\n",
      "Validation accuracy: 0.9948\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", clf.score(X_train, y_train_enc))\n",
    "print(\"Validation accuracy:\", clf.score(X_val, y_val_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b929f",
   "metadata": {},
   "source": [
    "To gather a more informational insight of the results, we can plot a confusion matrix. During evaluation we will only focus on the validation results. The reason for that is because we trained using the train dataset. Meaning, our model has already seen all those reviews and trained using them, meaning it is no suprise it scores good on it. The very high score on the validation set is what is truly incredible. 99.48% of the cases inside the validation set have been predicted correctly, even though the model has never seen those sentences before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8d5e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "cm = confusion_matrix(y_val_enc, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=le.classes_\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6241f76",
   "metadata": {},
   "source": [
    "From this confusion matrix we can see our model performance in more detail. First thing that stands out is the 100% accuracy on russian. Meaning that 500 out of 500 russian reviews have been predicted russian. When filtering the languages you would expect that the errors would have been mainly in between the three roman languages, spanish, italian and portuguese. That is not exactly the case. Yes there are some mistakes made between them, but they also make mistakes by predicting russian. For example, if we look at portuguese, it predicted 498/500 portuguese reviews as portuguese, but was mistaken once for italian and once for russian.\n",
    "\n",
    "There can be many reason for missclassifications. Perhaps, most of the words in the sentence were unknown to the classifier? Maybe english language is used in russian reviews during training? We can find the sentences that have been missclassified, to attempt to understand why they have been missclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27f4e3",
   "metadata": {},
   "source": [
    "Tokens and unknown word count statistics for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0be8847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Index True Predicted  Tokens  UNK count  UNK %\n",
      "   524   es        pt       4          0   0.00\n",
      "   530   en        it       5          0   0.00\n",
      "   596   en        pt       5          1  20.00\n",
      "   601   it        pt      10          3  30.00\n",
      "   695   es        it       4          1  25.00\n",
      "   817   en        ru       5          1  20.00\n",
      "   852   es        ru      13          1   7.69\n",
      "  1221   es        ru       6          1  16.67\n",
      "  1303   pt        ru       4          2  50.00\n",
      "  1617   en        ru      11          1   9.09\n",
      "  1710   es        pt       8          1  12.50\n",
      "  2098   en        ru       4          1  25.00\n",
      "  2497   pt        it       9          3  33.33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Show full text in DataFrames\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Ensure reviews are strings\n",
    "reviews_val = [str(r) for r in reviews_val]\n",
    "\n",
    "# Find wrong predictions\n",
    "wrong_mask = y_val_enc != y_pred\n",
    "wrong_indices = np.where(wrong_mask)[0]\n",
    "\n",
    "# Build DataFrame\n",
    "wrong_df = pd.DataFrame({\n",
    "    \"Index\": wrong_indices,\n",
    "    \"True\": [le.classes_[y_val_enc[i]] for i in wrong_indices],\n",
    "    \"Predicted\": [le.classes_[y_pred[i]] for i in wrong_indices],\n",
    "    \"Tokens\": [len(tokenizer(reviews_val[i])) for i in wrong_indices],\n",
    "    \"UNK count\": [tokenizer(reviews_val[i]).count(0) for i in wrong_indices],\n",
    "})\n",
    "\n",
    "# Calculate UNK percentage\n",
    "wrong_df[\"UNK %\"] = (wrong_df[\"UNK count\"] / wrong_df[\"Tokens\"] * 100).round(2)\n",
    "\n",
    "# Print nicely\n",
    "print(wrong_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2894218",
   "metadata": {},
   "source": [
    "Full sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d60465d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 524\n",
      "True: es\n",
      "Predicted: pt\n",
      "UNK count: 0/4 (0.0%)\n",
      "Text: Llego antes de tiempo\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 530\n",
      "True: en\n",
      "Predicted: it\n",
      "UNK count: 0/5 (0.0%)\n",
      "Text: Mother in law loved them\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 596\n",
      "True: en\n",
      "Predicted: pt\n",
      "UNK count: 1/5 (20.0%)\n",
      "Text: Geared more towards sight reading\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 601\n",
      "True: it\n",
      "Predicted: pt\n",
      "UNK count: 3/10 (30.0%)\n",
      "Text: Sly Stallone's Sone Sage trovato morto a Los Angeles\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 695\n",
      "True: es\n",
      "Predicted: it\n",
      "UNK count: 1/4 (25.0%)\n",
      "Text: Desempeña su función correctamente\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 817\n",
      "True: en\n",
      "Predicted: ru\n",
      "UNK count: 1/5 (20.0%)\n",
      "Text: Makes your pee orange.\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 852\n",
      "True: es\n",
      "Predicted: ru\n",
      "UNK count: 1/13 (7.7%)\n",
      "Text: Funcionaron bien 10 salidas.... después ruido...\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 1221\n",
      "True: es\n",
      "Predicted: ru\n",
      "UNK count: 1/6 (16.7%)\n",
      "Text: El repartidor decidió unilateralmente devolverlo.\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 1303\n",
      "True: pt\n",
      "Predicted: ru\n",
      "UNK count: 2/4 (50.0%)\n",
      "Text: Comentários desagradáveis, anonimato\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 1617\n",
      "True: en\n",
      "Predicted: ru\n",
      "UNK count: 1/11 (9.1%)\n",
      "Text: Jewels fall off alot. Had jewels off when arriving.\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 1710\n",
      "True: es\n",
      "Predicted: pt\n",
      "UNK count: 1/8 (12.5%)\n",
      "Text: velocidad de escritura 3 - 6 mb/s.\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 2098\n",
      "True: en\n",
      "Predicted: ru\n",
      "UNK count: 1/4 (25.0%)\n",
      "Text: Makes crafting easy.\n",
      "--------------------------------------------------------------------------------\n",
      "Index: 2497\n",
      "True: pt\n",
      "Predicted: it\n",
      "UNK count: 3/9 (33.3%)\n",
      "Text: Sly Stallone's Sone Sage encontrado morto em LA\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create mask for wrong predictions\n",
    "wrong_mask = y_val_enc != y_pred\n",
    "wrong_indices = np.where(wrong_mask)[0]\n",
    "\n",
    "# Loop over wrong predictions for clean left-aligned print\n",
    "for i in wrong_indices:\n",
    "    tokens = tokenizer(reviews_val[i])\n",
    "    unk_count = tokens.count(0)\n",
    "    total_tokens = len(tokens)\n",
    "    unk_percent = (unk_count / total_tokens * 100) if total_tokens > 0 else 0\n",
    "    \n",
    "    print(f\"Index: {i}\")\n",
    "    print(f\"True: {le.classes_[y_val_enc[i]]}\")\n",
    "    print(f\"Predicted: {le.classes_[y_pred[i]]}\")\n",
    "    print(f\"UNK count: {unk_count}/{total_tokens} ({unk_percent:.1f}%)\")\n",
    "    print(f\"Text: {reviews_val[i]}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25928ad",
   "metadata": {},
   "source": [
    "When looking at the missclassifications, it seems that most sentences have a low rate of unknown words. Meaning, that the errors made are likely due to the some data containing more than 1 language in a text. In other words, russian reviews using english, italian, spanish or portuguese words sometimes in their review. Another reason of missclassification is because some words are common in multiple languages. Words like \"In\" (English, Italian), \"de\" (Spanish, Portuguese), \"a\" (english, spanish, italian, portuguese) can all be reasons why the classifier is more leaning to a language than a another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affe836",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this tutorial we covered the key steps to create a basic text classifier:\n",
    "- **Collecting Data**: We downloaded the Language Identification dataset by papluca [[8]](#8-papluca-language-identification-dataset-hugging-face-httpshuggingfacecodatasetspaplucalanguage-identification).\n",
    "- **Data Preperation**: We filtered the dataset to 5 languages, tokenized our input, represented our data as bag-of-words and encoded our labels.\n",
    "- **Modelling**: trained a language classifier.\n",
    "- **Evaluation**: evaluated our model's performance.\n",
    "\n",
    "If you want to dive deeper into text classification, I highly recommend reading Chapter 14 of *Deep Learning with Python* by François Chollet [[1]](#1-francois-chollet-deep-learning-with-python-third-edition-chapter-14-text-classification-httpsdeeplearningwithpythoniochapterschapter14_text-classification). This tutorial was mostly inspired by that chapter, which provides a strong foundation in text classification.\n",
    "\n",
    "Once you feel comfortable with set-based models, you can move on to sequence-based models. The big difference between set- and sequence-based models is that sequence-based models **do** take word order into account. Together, set-based and sequence-based models form the foundation of most text classification methods, so understanding both of these is the most logical first step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50763502",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- ##### [1] Francois Chollet. *Deep Learning with Python*, Third Edition, Chapter 14: Text Classification. https://deeplearningwithpython.io/chapters/chapter14_text-classification/\n",
    "- ##### [2] pandas developers. *Getting started (pandas 2.3.3 documentation)*. https://pandas.pydata.org/pandas-docs/version/2.3.3/getting_started/index.html \n",
    "- ##### [3] fsspec developers. *fsspec documentation (latest)*. https://filesystem-spec.readthedocs.io/en/latest/\n",
    "- ##### [4] Hugging Face developers. *huggingface_hub documentation (latest)*. https://huggingface.co/docs/huggingface_hub/\n",
    "- ##### [5] scikit-learn developers. *scikit-learn 1.7.2 documentation*. https://scikit-learn.org/1.7/\n",
    "- ##### [6] Matplotlib developers. *Matplotlib 3.10.8 documentation*. https://matplotlib.org/3.10.8/\n",
    "- ##### [7] Seaborn developers. *Seaborn documentation*. https://seaborn.pydata.org/\n",
    "- ##### [8] papluca. *Language Identification dataset*. Hugging Face. https://huggingface.co/datasets/papluca/language-identification\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
